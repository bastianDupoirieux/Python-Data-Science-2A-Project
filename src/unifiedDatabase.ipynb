{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfcb4e6",
   "metadata": {},
   "source": [
    "# Creating two unified databases, with only the necessary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293095e2",
   "metadata": {},
   "source": [
    "We are going to create a database with the largest train stations in each country of interest. \n",
    "\n",
    "These countries are France, Belgium, Switzerland, Germany and Austria. Furthermore, we can look at the trains in other parts of Europe aswell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc0707",
   "metadata": {},
   "source": [
    "We'll use a webscraping method to collect the information on a country, and save the list of cities we'll consider in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n",
    "!pip install pandas fiona shapely pyproj rtree \n",
    "!pip install geopandas\n",
    "!pip install folium\n",
    "\n",
    "\"Libraries Import\"\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f71bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import countriesAndCities\n",
    "import dataGathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50054ca6",
   "metadata": {},
   "source": [
    "We will create a dictionary for Austria and Germany, containing each countries' largest train stations, based on these two links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStation = dict()\n",
    "\n",
    "urlGermany = 'https://bahnauskunft.info/bahnhoefe-deutschland/'\n",
    "urlAustria = 'https://www.omio.at/bahnhoefe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd168ffc",
   "metadata": {},
   "source": [
    "At the same time, we will have to change certain dictionary keys. As such, we can create a function that does exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeKeys(country, valueToChange, newValue):\n",
    "    '''A method that takes the keys for a country in the largestStations dictionary, and replacey certain values\n",
    "     @param country: the country with a value to change, of type string\n",
    "     @param valueToChange: the value in the key to change\n",
    "     @param newValue: the new value in the key\n",
    "     @return largestStations: a dictionary with the information, of type dict'''\n",
    "    listKeys = list(largestStations[country].keys())\n",
    "    oldKeys = []\n",
    "    for i in range (len(listKeys)):\n",
    "        station = listKeys[i]\n",
    "        if valueToChange in listKeys[i]:\n",
    "            oldKey = station\n",
    "            oldKeys.append(oldKey)\n",
    "            newKey = station.replace(valueToChange, '') + newValue\n",
    "            largestStations[country][newKey] = largestStations[country][oldKey]\n",
    "    \n",
    "    for station in oldKeys:\n",
    "        largestStations[country].pop(station)\n",
    "    \n",
    "    return(largestStations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49010e",
   "metadata": {},
   "source": [
    "# 1. Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bcb18",
   "metadata": {},
   "source": [
    "We'll start by getting the different relevant cities for Germany, and then working on the different geojson files to create a relevant database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e762ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations['Germany'] = dataGathering.gather(urlGermany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505265ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91691c10",
   "metadata": {},
   "source": [
    "The deutsche Bahn's database uses 'Hbf' instead of 'Hauptbahnhof' so we must change the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations = changeKeys('Germany', 'Hauptbahnhof', 'Hbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2df83",
   "metadata": {},
   "source": [
    "# 1.1. Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73c91e",
   "metadata": {},
   "source": [
    "We'll start by creating a database of all stations in the selected cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = 'Germany/railwayStationNodes.geojson'\n",
    "\n",
    "deutscheBahnStations = gpd.read_file(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1383cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deutscheBahnStations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ffe58",
   "metadata": {},
   "source": [
    "We can start by dropping the column containing the nature of the node, and the index of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2884e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deutscheBahnStations = deutscheBahnStations.drop('formOfNode', axis = 1)\n",
    "deutscheBahnStations = deutscheBahnStations.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74375435",
   "metadata": {},
   "outputs": [],
   "source": [
    "deutscheBahnStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db38e3",
   "metadata": {},
   "source": [
    "We check, for every single row, if the name of the station is located in one of the select few cities. The name of the station is the third value (index 2) of each row\n",
    "Furthermore, we check that there is space after the name of each city, as to avoid other cities with street names (as in Berlin -> Berliner)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a6527",
   "metadata": {},
   "source": [
    "We are going to select every line containing data on a station in one of the cities, and concatenate every one of these separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListStations = []\n",
    "for station in (list(largestStations['Germany'].keys())):\n",
    "    tempFrame = deutscheBahnStations.loc[deutscheBahnStations['geographicalName'] == station]\n",
    "    dfListStations.append(tempFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39d6bc",
   "metadata": {},
   "source": [
    "We define the geodataframe with the chosen coordinate system, EPSG:4258 (documentation available at https://www.geoportal.de/Metadata/55134453-193d-47ea-9b20-0f7016702c91, in german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations = gpd.GeoDataFrame(pd.concat(dfListStations, ignore_index=True), crs=4258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046f09f",
   "metadata": {},
   "source": [
    "Certain nodes are the same station. We will keep a single occurence of every station, based on the railwayStationCode variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations = workFrameStations.drop_duplicates(subset='railwayStationCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63beed",
   "metadata": {},
   "source": [
    "Finally, we can add a column, indicating that every value in this geodataframe is located in Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e87190",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations.insert(0, 'country', ['Germany']*len(workFrameStations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a95e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bddea6",
   "metadata": {},
   "source": [
    "# 1.2. Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb2d44",
   "metadata": {},
   "source": [
    "We can do the exact same thing the dataframe of the different train lines. However, the information is segmented, and as such we cannot remove any row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "deutscheBahnLines = gpd.read_file('Germany/railwayLines.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "deutscheBahnLines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd55a0",
   "metadata": {},
   "source": [
    "# 2. Austria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17a511",
   "metadata": {},
   "source": [
    "We now have a database with the different stations and lines in Germany. We will now add the values for Austria to this database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations['Austria'] = dataGathering.gather(urlAustria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413a717",
   "metadata": {},
   "source": [
    "This database does the exact opposite of the German database. It uses 'Hauptbahnhof', whereas we had values with 'Hbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ab9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "largestStations = changeKeys('Austria', 'Hbf', 'Hauptbahnhof')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef535562",
   "metadata": {},
   "source": [
    "# 2.1. Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsAustria = 'Austria/GIP_Betriebsstellen_DelEUV_JSON.json'\n",
    "stationsAustriaFrame = gpd.read_file(stationsAustria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsAustriaFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd23873",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsAustriaFrame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282bcac",
   "metadata": {},
   "source": [
    "Quite a few columns here are useless. We can remove these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToRemove = ['BSTS_ID', 'DB640_CODE', 'OBJECTID', 'GIP_OBID', 'EXTERNALID', 'REGIONALCO', 'VALIDFROM', 'VALIDTO', 'OWNER_NAME', 'PV_EVA_NR', 'ANZ_AUFZUG', 'ANZ_FAHRTR', 'ANZ_UHREN',\n",
    "                  'ANZ_AKUSTI','ANZ_OPTISC', 'INFOPOINT', 'MUEZ', 'MUEZ_KURZ', 'HILFE_MOBI', 'ANZ_ROLLST', 'ANZ_E_LADE', 'RUD_PARKPL', 'VERIFIZIER',\n",
    "                  'PUBL_WLAN', 'MUEZ_LANG', 'BEMERKUNG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a75e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columnsToRemove:\n",
    "    stationsAustriaFrame = stationsAustriaFrame.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsAustriaFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6651c0c",
   "metadata": {},
   "source": [
    "We can now focus on retrieving the rows with information on the two cities of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStationsAustria = []\n",
    "for station in largestStations['Austria']:\n",
    "    tempFrame = stationsAustriaFrame.loc[stationsAustriaFrame['NAME_FPL'] == station]\n",
    "    dfStationsAustria.append(tempFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStationsAustria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameAustria = gpd.GeoDataFrame(pd.concat(dfStationsAustria), crs = 31287)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameAustria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8ca7f",
   "metadata": {},
   "source": [
    "Add the country to the work dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc979ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameAustria.insert(0, 'country', ['Austria']*len(workFrameAustria))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad51d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFrameAustria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32149637",
   "metadata": {},
   "source": [
    "# 2.2. Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed38865",
   "metadata": {},
   "source": [
    "We can do the exact same with the train lines database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linesAustria = 'Austria/GIP_Strecken_MLA.json'\n",
    "linesAustriaFrame = gpd.read_file(linesAustria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linesAustriaFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827709e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linesAustriaFrame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c577f8",
   "metadata": {},
   "source": [
    "Once again, quite a few columns are useless, and we can get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c160a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uselessColumns = ['GIP_OBID', 'BST_ID', 'FOW_NAME', 'FRC_NAME', 'REGION', 'VALIDFROM', 'VALIDTO', 'CROSSSECT', 'CROSS_NAME', \n",
    "                  'ELEKTRI', 'EXPDATE']\n",
    "\n",
    "for column in uselessColumns:\n",
    "    linesAustriaFrame = linesAustriaFrame.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d81c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "linesAustriaFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9030c",
   "metadata": {},
   "source": [
    "# 3. Swtitzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc748e",
   "metadata": {},
   "source": [
    "# 3.1. Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5607b8",
   "metadata": {},
   "source": [
    "I use the BAV_List_future_timetable.xlsx from https://opentransportdata.swiss/fr/dataset/bav_liste that I named suissedata1.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_excel('suissedata1.xlsx')\n",
    "df=df.drop(columns=['Remarque','Statut','Localité','N° commune','Ct.','Carte','Carte.1','N° sv.85','py','N° sv.','Cc','PE','PT','N° ET','Sigle ET','N° GO','Sigle GO','Nom long','Sigle sv.','PC','PP','ST'])\n",
    "df.head()\n",
    "\n",
    "\n",
    "#We only use the dataframe where the transport is equal to 'Zug' (Train)\n",
    "\n",
    "df1=df.copy()\n",
    "\n",
    "df1=df1[df1['Moyen de transport']=='Zug']\n",
    "df1.head()\n",
    "\n",
    "\n",
    "df2=df1[df1['Longueur']>20]\n",
    "df3=df2.drop(columns=['Longueur', 'Moyen de transport','Altitude','Commune'])\n",
    "df3.head()\n",
    "\n",
    "\n",
    "final_df=df3.assign(Pays=\"Suisse\")\n",
    "final_df.head()\n",
    "final_df.to_csv(r'stations.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e1da3",
   "metadata": {},
   "source": [
    "# 3.2. Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced598ec",
   "metadata": {},
   "source": [
    "I use a geojson you can find on https://data.sbb.ch/explore/dataset/linie-mit-polygon/export/?fbclid=IwAR3vTCN6GkY4UXZRrm4RNjTRIn726lOGLZmni_K_bi5s-XjerqQ9eCemsrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "print(folium.__version__)\n",
    "\n",
    "lines_suisse=gpd.read_file('linie-mit-polygon.geojson')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311be7c",
   "metadata": {},
   "source": [
    "We are left with an id for the line, the name of the line, the geographical region in which the line lies (between 'NODEFROM' and 'NODETO'), and the geometry of the lines.\n",
    "\n",
    "We can't get rid of any further rows, as each row contains unique geometric information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93a184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
